{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e480eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b667ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = glob('trainval/*/*_image.jpg')\n",
    "targets = glob('trainval/*/*_bbox.bin')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754a3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = PrepareDataset(inputs=inputs,\n",
    "                        targets=targets)\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=2,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12284012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          ...,\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779]],\n",
       " \n",
       "         [[-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          ...,\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779]],\n",
       " \n",
       "         [[-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          [-1.6555, -1.7206, -1.5604],\n",
       "          ...,\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779],\n",
       "          [-1.8610, -1.8081, -1.5779]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.5519, -1.5548, -1.3010],\n",
       "          [-1.6129, -1.6134, -1.3666],\n",
       "          [-1.6514, -1.6443, -1.4015],\n",
       "          ...,\n",
       "          [-1.4595, -1.3597, -1.0327],\n",
       "          [-1.4203, -1.3226, -0.9899],\n",
       "          [-1.3243, -1.2244, -0.8922]],\n",
       " \n",
       "         [[-1.6465, -1.6382, -1.3645],\n",
       "          [-1.6663, -1.6681, -1.4174],\n",
       "          [-1.6214, -1.6157, -1.4070],\n",
       "          ...,\n",
       "          [-1.4329, -1.3338, -1.0043],\n",
       "          [-1.4165, -1.3187, -0.9860],\n",
       "          [-1.3590, -1.2599, -0.9275]],\n",
       " \n",
       "         [[-1.7138, -1.6946, -1.3835],\n",
       "          [-1.6745, -1.6764, -1.4183],\n",
       "          [-1.5900, -1.5835, -1.3817],\n",
       "          ...,\n",
       "          [-1.4366, -1.3342, -1.0114],\n",
       "          [-1.3969, -1.2986, -0.9660],\n",
       "          [-1.2482, -1.1466, -0.8147]]]),\n",
       " 'y': {'boxes': array([522, 210, 677, 302]),\n",
       "  'labels': tensor([1], dtype=torch.uint8)},\n",
       " 'x_name': 'trainval/fold1/0000_image.jpg',\n",
       " 'y_name': 'trainval/fold1/0000_bbox.bin'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cae5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.zeros((3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972bb1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(a, (2,0,1)).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e872eb21e299ead846688b5d96ad52069916ec7bc2e600e8ed4cb5254daabd4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
